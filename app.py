"""
FastAPI æœåŠ¡æ¨¡å—
å°† langgraph-fastmcp çš„ agent åŠŸèƒ½å°è£…ä¸º HTTP æœåŠ¡
"""

import asyncio
import json
import os
from contextlib import asynccontextmanager
from typing import Optional, AsyncGenerator

from fastapi import FastAPI, HTTPException
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from mcp import StdioServerParameters
from loguru import logger

from states import PlannerState
from worker import mcp_client
from utils import log_step

# åˆ›å»ºä¸€ä¸ªå…¨å±€äº‹ä»¶é˜Ÿåˆ—ç”¨äºæµå¼è¾“å‡º
event_queue: asyncio.Queue = None


def get_event_queue() -> asyncio.Queue:
    """è·å–æˆ–åˆ›å»ºå…¨å±€äº‹ä»¶é˜Ÿåˆ—"""
    global event_queue
    if event_queue is None:
        event_queue = asyncio.Queue()
    return event_queue


async def put_event(event_type: str, content: str):
    """å‘äº‹ä»¶é˜Ÿåˆ—æ·»åŠ äº‹ä»¶"""
    global event_queue
    if event_queue is not None:
        await event_queue.put({"type": event_type, "content": content})


async def clear_events():
    """æ¸…ç©ºäº‹ä»¶é˜Ÿåˆ—"""
    global event_queue
    if event_queue is not None:
        while not event_queue.empty():
            try:
                event_queue.get_nowait()
            except asyncio.QueueEmpty:
                break


# ============= è‡ªå®šä¹‰å›¾èŠ‚ç‚¹å‡½æ•° (å†…è”å®ç°ä»¥æ”¯æŒæµå¼è¾“å‡º) =============

async def planning_with_stream(state: PlannerState) -> PlannerState:
    """è§„åˆ’èŠ‚ç‚¹: ç”Ÿæˆ JSON æ ¼å¼çš„ä»»åŠ¡è®¡åˆ’ (å¸¦æµå¼è¾“å‡º)"""
    from planner import build_planner_prompt, get_llm, Plan
    import re
    
    user_input = state["user_input"]
    
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“‹ è§„åˆ’èŠ‚ç‚¹ - å¼€å§‹åˆ†æç”¨æˆ·éœ€æ±‚...")
    logger.info(f"{'='*60}")
    logger.info(f"ç”¨æˆ·è¾“å…¥: {user_input}\n")
    
    await put_event("phase", "ğŸ“‹ è§„åˆ’é˜¶æ®µ - å¼€å§‹åˆ†æç”¨æˆ·éœ€æ±‚...")
    
    logger.info("å¼€å§‹è·å– MCP å·¥å…·åˆ—è¡¨...")
    
    try:
        # è·å– MCP å·¥å…·ç”¨äºç”Ÿæˆæè¿°
        mcp_tools = await mcp_client.list_tools()
        logger.info(f"âœ… æˆåŠŸè·å– {len(mcp_tools)} ä¸ªå¯ç”¨å·¥å…·")
        
        # è®°å½•æ¯ä¸ªå·¥å…·çš„è¯¦ç»†ä¿¡æ¯
        for tool in mcp_tools:
            logger.debug(f"  - å·¥å…·åç§°: {tool.name}")
            logger.debug(f"    æè¿°: {tool.description if hasattr(tool, 'description') else 'æ— æè¿°'}")
        
        await put_event("info", f"è·å–åˆ° {len(mcp_tools)} ä¸ªå¯ç”¨å·¥å…·")
        
        # ç”ŸæˆåŒ…å«å·¥å…·ä¿¡æ¯çš„ prompt
        planner_prompt = build_planner_prompt(mcp_tools)
        
        logger.info(f"Planner Prompt é•¿åº¦: {len(planner_prompt)} å­—ç¬¦")
        logger.info(f"å®Œæ•´ Planner Prompt:\n{planner_prompt}")
        
        await put_event("info", "æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆä»»åŠ¡è®¡åˆ’...")
        
        logger.info("ğŸš€ å¼€å§‹è°ƒç”¨ LLM (è§„åˆ’èŠ‚ç‚¹)...")
        logger.info(f"LLM é…ç½®: temperature=0.7, model={os.getenv('OPENAI_MODEL', 'gpt-4')}")
        
        # ä¸ä½¿ç”¨ bind_tools,è®© LLM è¿”å› JSON æ ¼å¼çš„è®¡åˆ’
        llm = get_llm(temperature=0.7)
        
        # è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’
        messages = [
            {"role": "system", "content": planner_prompt},
            {"role": "user", "content": user_input}
        ]
        
        logger.debug(f"LLM è¾“å…¥æ¶ˆæ¯æ•°é‡: {len(messages)}")
        logger.debug(f"ç”¨æˆ·æ¶ˆæ¯é•¿åº¦: {len(user_input)} å­—ç¬¦")
        
        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        chunk_count = 0
        async for chunk in llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                full_content += chunk.content
                chunk_count += 1
        
        logger.info(f"âœ… LLM å“åº”å®Œæˆï¼Œå…± {chunk_count} ä¸ª chunkï¼Œæ€»é•¿åº¦: {len(full_content)} å­—ç¬¦")
        logger.info(f"å®Œæ•´ LLM å“åº”:\n{full_content}")
        
        await put_event("info", f"LLM å“åº”å®Œæˆï¼Œå†…å®¹é•¿åº¦: {len(full_content)} å­—ç¬¦")
        
        # è§£æå“åº”
        if full_content:
            # å°è¯•è§£æ JSON æ ¼å¼çš„è®¡åˆ’
            try:
                # æå– JSON
                if "```json" in full_content:
                    start = full_content.find("```json") + 7
                    end = full_content.find("```", start)
                    json_str = full_content[start:end].strip()
                elif "```" in full_content:
                    start = full_content.find("```") + 3
                    end = full_content.find("```", start)
                    json_str = full_content[start:end].strip()
                else:
                    json_str = full_content.strip()
                
                await put_event("info", f"æå–åˆ° JSON æ ¼å¼è®¡åˆ’")
                
                plan_data = json.loads(json_str)
                plan = Plan(**plan_data)
                
                logger.success(f"âœ… è®¡åˆ’ç”ŸæˆæˆåŠŸï¼Œå…± {len(plan.tasks)} ä¸ªä»»åŠ¡")
                logger.info(f"å®Œæ•´è®¡åˆ’è¯¦æƒ…: {json.dumps(plan.model_dump(), indent=2, ensure_ascii=False)}")
                
                # è¾“å‡ºæ¯ä¸ªä»»åŠ¡
                for task in plan.tasks:
                    logger.info(f"  ä»»åŠ¡ [{task.task_id}]: {task.description}")
                    logger.info(f"    å·¥å…·: {task.tool}")
                    logger.info(f"    å‚æ•°: {task.arguments}")
                    logger.info(f"    ä¾èµ–: {task.depends_on}")
                
                await put_event("plan_ready", f"âœ… è®¡åˆ’ç”Ÿæˆå®Œæˆï¼Œå…± {len(plan.tasks)} ä¸ªä»»åŠ¡")
                
                # è¾“å‡ºæ¯ä¸ªä»»åŠ¡
                for task in plan.tasks:
                    await put_event("task", f"[{task.task_id}] {task.description} (å·¥å…·: {task.tool})")
                
                state["plan"] = plan
                state["task_results"] = {}
                
            except json.JSONDecodeError as e:
                logger.error(f"âŒ JSON è§£æå¤±è´¥: {str(e)}")
                logger.error(f"JSON è§£æä½ç½®: {e.pos}")
                logger.error(f"åŸå§‹å†…å®¹å‰200å­—ç¬¦: {full_content[:200]}")
                await put_event("error", f"JSON è§£æå¤±è´¥: {str(e)}")
                state["error"] = f"JSON è§£æå¤±è´¥: {str(e)}\nåŸå§‹å†…å®¹: {full_content[:200]}"
            except Exception as e:
                logger.error(f"âŒ è§£æè®¡åˆ’å¤±è´¥: {str(e)}")
                import traceback
                logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                await put_event("error", f"è§£æè®¡åˆ’å¤±è´¥: {str(e)}")
                state["error"] = f"è§£æè®¡åˆ’å¤±è´¥: {str(e)}"
        else:
            logger.error("âŒ LLM æœªè¿”å›æœ‰æ•ˆå†…å®¹")
            await put_event("error", "LLM æœªè¿”å›æœ‰æ•ˆå†…å®¹")
            state["error"] = "LLM æœªè¿”å›æœ‰æ•ˆå†…å®¹"
        
    except Exception as e:
        logger.error(f"âŒ è§„åˆ’èŠ‚ç‚¹é”™è¯¯: {str(e)}")
        import traceback
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        await put_event("error", f"è§„åˆ’èŠ‚ç‚¹é”™è¯¯: {str(e)}")
        state["error"] = f"è§„åˆ’èŠ‚ç‚¹é”™è¯¯: {str(e)}"
    
    return state


async def execution_with_stream(state: PlannerState) -> PlannerState:
    """æ‰§è¡ŒèŠ‚ç‚¹: æ‰§è¡Œå·¥å…·è°ƒç”¨ (å¸¦æµå¼è¾“å‡º)"""
    from tools import get_langchain_tools
    from planner import (
        resolve_task_dependencies, auto_add_dependencies, extract_metric_name
    )
    
    plan = state.get("plan")
    if not plan:
        logger.error("âŒ æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’")
        state["error"] = "æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’"
        return state
    
    logger.info(f"\n{'='*60}")
    logger.info("âš¡ æ‰§è¡ŒèŠ‚ç‚¹ - å¼€å§‹æ‰§è¡Œå·¥å…·è°ƒç”¨")
    logger.info(f"{'='*60}")
    logger.info(f"æ€»ä»»åŠ¡æ•°: {len(plan.tasks)}")
    
    await put_event("phase", f"âš¡ æ‰§è¡Œé˜¶æ®µ - å¼€å§‹æ‰§è¡Œ {len(plan.tasks)} ä¸ªä»»åŠ¡")
    
    try:
        # è·å– LangChain å·¥å…·
        logger.info("å¼€å§‹è·å– LangChain å·¥å…·...")
        tools = await get_langchain_tools(mcp_client)
        logger.info(f"âœ… æˆåŠŸè·å– {len(tools)} ä¸ª LangChain å·¥å…·")
        
        # è®°å½•å¯ç”¨å·¥å…·
        for tool in tools:
            logger.debug(f"  - {tool.name}: {tool.description}")
        
        task_results = state.get("task_results", {})
        executed_tasks = set()
        
        # é¢„å¤„ç†ï¼šè‡ªåŠ¨åˆ†æå¹¶æ·»åŠ ä»»åŠ¡ä¾èµ–
        logger.info("å¼€å§‹åˆ†æä»»åŠ¡ä¾èµ–å…³ç³»...")
        auto_add_dependencies(plan)
        logger.info("âœ… ä»»åŠ¡ä¾èµ–åˆ†æå®Œæˆ")
        
        await put_event("info", f"ä»»åŠ¡ä¾èµ–åˆ†æå®Œæˆï¼Œå‡†å¤‡æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œ")
        
        # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œä»»åŠ¡
        while len(executed_tasks) < len(plan.tasks):
            # æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡
            ready_tasks = [
                task for task in plan.tasks
                if task.task_id not in executed_tasks
                and all(dep in executed_tasks for dep in task.depends_on)
            ]
            
            if not ready_tasks:
                remaining = [t for t in plan.tasks if t.task_id not in executed_tasks]
                state["error"] = f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–: {[t.task_id for t in remaining]}"
                await put_event("error", state["error"])
                break
            
            # æ‰§è¡Œå°±ç»ªçš„ä»»åŠ¡
            for task in ready_tasks:
                logger.info(f"\n{'-'*60}")
                logger.info(f"ğŸ”§ å¼€å§‹æ‰§è¡Œä»»åŠ¡ [{task.task_id}]: {task.description}")
                logger.info(f"{'-'*60}")
                logger.info(f"å·¥å…·: {task.tool}")
                
                await put_event("executing", f"æ­£åœ¨æ‰§è¡Œä»»åŠ¡ [{task.task_id}]: {task.description}")
                
                try:
                    # è§£æå‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨
                    logger.debug("å¼€å§‹è§£æä»»åŠ¡å‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨...")
                    resolved_args = resolve_task_dependencies(task_results, plan, task)
                    logger.info(f"âœ… å‚æ•°è§£æå®Œæˆ: {resolved_args}")
                    
                    # æ˜¾ç¤ºå‚æ•°
                    args_str = ", ".join([f"{k}={v}" for k, v in resolved_args.items()])
                    logger.info(f"å‚æ•°è¯¦æƒ…: {args_str}")
                    await put_event("info", f"  å‚æ•°: {args_str}")
                    
                    # ç‰¹æ®Šå¤„ç†ï¼šquery_sales_summary_detail éœ€è¦æŸ¥è¯¢ metric_name
                    if task.tool == "query_sales_summary_detail":
                        metric_name_input = resolved_args.get("metric_name", "")
                        if isinstance(metric_name_input, str) and not metric_name_input.startswith("${"):
                            logger.info(f"ğŸ” éœ€è¦æŸ¥è¯¢æŒ‡æ ‡: {metric_name_input}")
                            await put_event("info", f"  è‡ªåŠ¨è°ƒç”¨ search_metrics æŸ¥è¯¢æŒ‡æ ‡: {metric_name_input}")
                            search_tool = next((t for t in tools if t.name == "search_metrics"), None)
                            if search_tool:
                                logger.info(f"è°ƒç”¨ search_metrics å·¥å…·...")
                                search_result = await search_tool.ainvoke({
                                    "value": metric_name_input,
                                    "column_name": "metric_name_cn",
                                    "n_results": 1
                                })
                                logger.info(f"search_metrics ç»“æœ: {search_result}")
                                resolved_args["metric_name"] = extract_metric_name(str(search_result)) or metric_name_input
                                logger.info(f"âœ… è§£æåˆ° metric_name: {resolved_args['metric_name']}")
                                await put_event("info", f"  è§£æåˆ° metric_name: {resolved_args['metric_name']}")
                    
                    # æ‰¾åˆ°å¯¹åº”çš„å·¥å…·
                    logger.info(f"æŸ¥æ‰¾å·¥å…·: {task.tool}")
                    tool = next((t for t in tools if t.name == task.tool), None)
                    if not tool:
                        logger.error(f"âŒ å·¥å…·æœªæ‰¾åˆ°: {task.tool}")
                        raise ValueError(f"å·¥å…·æœªæ‰¾åˆ°: {task.tool}")
                    
                    # æ‰§è¡Œå·¥å…·
                    logger.info(f"ğŸš€ è°ƒç”¨å·¥å…· [{task.tool}]...")
                    logger.info(f"å·¥å…·å‚æ•°: {resolved_args}")
                    await put_event("info", f"  è°ƒç”¨ {task.tool}...")
                    
                    # è®°å½•å·¥å…·è°ƒç”¨å¼€å§‹æ—¶é—´
                    import time
                    start_time = time.time()
                    
                    result = await tool.ainvoke(resolved_args)
                    
                    # è®°å½•å·¥å…·è°ƒç”¨è€—æ—¶
                    elapsed_time = time.time() - start_time
                    logger.info(f"âœ… å·¥å…·è°ƒç”¨å®Œæˆï¼Œè€—æ—¶: {elapsed_time:.2f} ç§’")
                    
                    task.status = "completed"
                    task.result = result
                    task_results[task.task_id] = result
                    
                    logger.success(f"âœ… ä»»åŠ¡ [{task.task_id}] å®Œæˆ")
                    logger.info(f"å®Œæ•´ç»“æœ: {result}")
                    await put_event("complete", f"âœ… ä»»åŠ¡ [{task.task_id}] å®Œæˆ")
                
                except Exception as e:
                    logger.error(f"âŒ ä»»åŠ¡ [{task.task_id}] æ‰§è¡Œå¤±è´¥: {str(e)}")
                    import traceback
                    logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
                    await put_event("error", f"âŒ ä»»åŠ¡ [{task.task_id}] å¤±è´¥: {str(e)}")
                    task.status = "failed"
                    task.error = str(e)
                    task_results[task.task_id] = {"error": str(e)}
                
                executed_tasks.add(task.task_id)
        
        state["task_results"] = task_results
        
        logger.success(f"\n{'='*60}")
        logger.success(f"âœ… æ‰€æœ‰ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼Œå…± {len(executed_tasks)} ä¸ªä»»åŠ¡")
        logger.success(f"{'='*60}\n")
        
    except Exception as e:
        logger.error(f"âŒ æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {str(e)}")
        import traceback
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        await put_event("error", f"æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {str(e)}")
        state["error"] = f"æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {str(e)}"
    
    return state


async def final_answer_with_stream(state: PlannerState) -> PlannerState:
    """æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹: æ±‡æ€»æ‰€æœ‰ä»»åŠ¡ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ (å¸¦æµå¼è¾“å‡º)"""
    from planner import get_llm
    
    plan = state.get("plan")
    task_results = state.get("task_results", {})
    
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ’¡ æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹ - ç”Ÿæˆç­”æ¡ˆ...")
    logger.info(f"{'='*60}")
    logger.info("\nğŸ“Š ä»»åŠ¡æ‰§è¡Œæ‘˜è¦:")
    for task in plan.tasks:
        logger.info(f"  - ä»»åŠ¡ {task.task_id}: {task.status}")
    
    await put_event("phase", "ğŸ’¡ æœ€ç»ˆç­”æ¡ˆé˜¶æ®µ - æ­£åœ¨ç”Ÿæˆç­”æ¡ˆ...")
    
    # æ„å»ºç»“æœæ‘˜è¦
    summary = []
    for task in plan.tasks:
        summary.append(f"ä»»åŠ¡ {task.task_id} ({task.description}):")
        summary.append(f"  çŠ¶æ€: {task.status}")
        if task.result:
            summary.append(f"  ç»“æœ: {task.result}")
        if task.error:
            summary.append(f"  é”™è¯¯: {task.error}")
    
    summary_text = "\n".join(summary)
    
    try:
        llm = get_llm(temperature=0.3)
        user_input = state.get("user_input", "")
        
        logger.info(f"LLM é…ç½®: temperature=0.3, model={os.getenv('OPENAI_MODEL', 'gpt-4')}")
        logger.info(f"ç”¨æˆ·åŸå§‹é—®é¢˜: {user_input}")
        logger.info(f"å®Œæ•´ä»»åŠ¡æ‘˜è¦:\n{summary_text}")
        
        await put_event("info", "æ­£åœ¨è°ƒç”¨ LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ...")
        
        logger.info("\nğŸš€ å¼€å§‹è°ƒç”¨ LLM (æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹)...")
        logger.info(f"{'-'*60}")
        
        messages = [
            {"role": "system", "content": "è¯·æ ¹æ®æ‰€æœ‰å­ä»»åŠ¡çš„æ‰§è¡Œç»“æœ,ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚è¦æ±‚ç®€æ´æ˜äº†,åŒ…å«å…³é”®ä¿¡æ¯ã€‚"},
            {"role": "user", "content": f"ç”¨æˆ·åŸå§‹é—®é¢˜: {user_input}\n\næ ¹æ®ä»»åŠ¡æ‰§è¡Œæ‘˜è¦,è¯·ç”Ÿæˆç”¨æˆ·æƒ³è¦äº†è§£çš„æœ€ç»ˆç­”æ¡ˆã€‚\n\nä»»åŠ¡æ‰§è¡Œæ‘˜è¦:\n{summary_text}"}
        ]
        
        # ä½¿ç”¨æµå¼è¾“å‡ºç”Ÿæˆç­”æ¡ˆ
        full_content = ""
        chunk_count = 0
        async for chunk in llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                content = chunk.content
                full_content += content
                chunk_count += 1
                # å®æ—¶è¾“å‡ºæ¯ä¸ªå­—ç¬¦
                await put_event("answer_chunk", content)
        
        logger.info(f"{'-'*60}")
        logger.success(f"âœ… LLM å“åº”å®Œæˆï¼Œå…± {chunk_count} ä¸ª chunkï¼Œæ€»é•¿åº¦: {len(full_content)} å­—ç¬¦")
        logger.info(f"å®Œæ•´æœ€ç»ˆç­”æ¡ˆ:\n{full_content}")
        
        await put_event("info", f"ç­”æ¡ˆç”Ÿæˆå®Œæˆï¼Œå…± {len(full_content)} å­—ç¬¦")
        
        state["final_answer"] = full_content
        
        logger.success(f"\n{'='*60}")
        logger.success("âœ… æœ€ç»ˆç­”æ¡ˆç”Ÿæˆå®Œæˆ")
        logger.success(f"å®Œæ•´æœ€ç»ˆç­”æ¡ˆ:\n{full_content}")
        logger.success(f"{'='*60}\n")
        
    except Exception as e:
        logger.error(f"âŒ ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}")
        import traceback
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        await put_event("error", f"ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}")
        state["final_answer"] = f"ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}\n\nä»»åŠ¡æ‘˜è¦:\n{summary_text}"
    
    return state


def should_execute(state: PlannerState) -> str:
    """æ¡ä»¶è¾¹: åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œä»»åŠ¡"""
    if state.get("error"):
        return "end"
    if not state.get("plan"):
        return "end"
    return "execute"


def create_planner_graph():
    """åˆ›å»º Planner ä¸»å›¾ (å†…è”å®ç°)"""
    from langgraph.graph import StateGraph, END
    
    workflow = StateGraph(PlannerState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("planning", planning_with_stream)
    workflow.add_node("execution", execution_with_stream)
    workflow.add_node("final_answer", final_answer_with_stream)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("planning")
    
    # æ·»åŠ è¾¹
    workflow.add_conditional_edges(
        "planning",
        should_execute,
        {
            "execute": "execution",
            "end": END
        }
    )
    
    workflow.add_edge("execution", "final_answer")
    workflow.add_edge("final_answer", END)
    
    return workflow.compile()


# å…¨å±€å˜é‡å­˜å‚¨å›¾å®ä¾‹
planner_graph = None


@asynccontextmanager
async def lifespan(app: FastAPI):
    """
    åº”ç”¨ç”Ÿå‘½å‘¨æœŸç®¡ç†
    å¯åŠ¨æ—¶åˆå§‹åŒ– MCP è¿æ¥,å…³é—­æ—¶æ¸…ç†
    """
    global planner_graph, event_queue
    
    # åˆå§‹åŒ–äº‹ä»¶é˜Ÿåˆ—
    event_queue = asyncio.Queue()
    
    # å¯åŠ¨æ—¶åˆå§‹åŒ–
    log_step("FastAPI æœåŠ¡", "å¯åŠ¨ä¸­...")
    
    # è¿æ¥ MCP æœåŠ¡å™¨
    server_params = StdioServerParameters(
        command=os.getenv("MCP_SERVER_COMMAND", "python"),
        args=[os.getenv("MCP_SERVER_ARGS", "mcp_server.py")],
        env=None
    )
    
    try:
        await mcp_client.connect(server_params)
        log_step("FastAPI æœåŠ¡", "âœ… MCP æœåŠ¡å™¨è¿æ¥æˆåŠŸ")
    except Exception as e:
        log_step("FastAPI æœåŠ¡", f"âŒ MCP æœåŠ¡å™¨è¿æ¥å¤±è´¥: {str(e)}")
        raise
    
    # åˆ›å»ºä¸»å›¾
    try:
        planner_graph = create_planner_graph()
        log_step("FastAPI æœåŠ¡", "âœ… Planner ä¸»å›¾æ„å»ºå®Œæˆ")
    except Exception as e:
        log_step("FastAPI æœåŠ¡", f"âŒ ä¸»å›¾æ„å»ºå¤±è´¥: {str(e)}")
        raise
    
    log_step("FastAPI æœåŠ¡", "âœ… æœåŠ¡å¯åŠ¨æˆåŠŸ")
    
    yield
    
    # å…³é—­æ—¶æ¸…ç†
    log_step("FastAPI æœåŠ¡", "å…³é—­ä¸­...")
    await mcp_client.close()
    log_step("FastAPI æœåŠ¡", "âœ… èµ„æºæ¸…ç†å®Œæˆ")


# åˆ›å»º FastAPI åº”ç”¨
app = FastAPI(
    title="LangGraph MCP Agent API",
    description="åŸºäº LangGraph å’Œ MCP çš„æ™ºèƒ½ä»£ç†ç³»ç»Ÿçš„ HTTP æœåŠ¡",
    version="1.0.0",
    lifespan=lifespan
)


# ============= è¯·æ±‚/å“åº”æ¨¡å‹ =============

class ChatRequest(BaseModel):
    """èŠå¤©è¯·æ±‚æ¨¡å‹"""
    user_input: str


class TaskInfo(BaseModel):
    """ä»»åŠ¡ä¿¡æ¯æ¨¡å‹"""
    task_id: str
    description: str
    tool: str
    status: str
    result: Optional[str] = None
    error: Optional[str] = None


class ChatResponse(BaseModel):
    """èŠå¤©å“åº”æ¨¡å‹"""
    success: bool
    final_answer: str = ""
    tasks: list[TaskInfo] = []
    error: Optional[str] = None


# ============= API ç«¯ç‚¹ =============

@app.get("/")
async def root():
    """æ ¹è·¯å¾„å¥åº·æ£€æŸ¥"""
    return {"status": "ok", "message": "LangGraph MCP Agent API æœåŠ¡è¿è¡Œä¸­"}


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥ç«¯ç‚¹"""
    return {"status": "healthy"}


@app.post("/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """
    èŠå¤©æ¥å£
    
    æ¥æ”¶ç”¨æˆ·è¾“å…¥,æ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœ
    """
    global planner_graph
    
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“¥ æ”¶åˆ°æ–°çš„ API è¯·æ±‚")
    logger.info(f"{'='*60}")
    logger.info(f"ç«¯ç‚¹: /chat")
    logger.info(f"ç”¨æˆ·è¾“å…¥: {request.user_input}")
    logger.info(f"{'='*60}\n")
    
    if not request.user_input or not request.user_input.strip():
        logger.warning("âŒ ç”¨æˆ·è¾“å…¥ä¸ºç©º")
        raise HTTPException(status_code=400, detail="user_input ä¸èƒ½ä¸ºç©º")
    
    if planner_graph is None:
        logger.error("âŒ æœåŠ¡æœªå®Œå…¨åˆå§‹åŒ–")
        raise HTTPException(status_code=503, detail="æœåŠ¡æœªå®Œå…¨åˆå§‹åŒ–,è¯·ç¨åå†è¯•")
    
    log_step("API è¯·æ±‚", f"ç”¨æˆ·è¾“å…¥: {request.user_input}")
    
    # æ„å»ºåˆå§‹çŠ¶æ€
    initial_state: PlannerState = {
        "user_input": request.user_input,
        "plan": None,
        "task_results": {},
        "final_answer": "",
        "error": None
    }
    
    try:
        logger.info("å¼€å§‹æ‰§è¡Œä¸»å›¾...")
        # æ‰§è¡Œä¸»å›¾
        final_state = await planner_graph.ainvoke(initial_state)
        
        logger.info("ä¸»å›¾æ‰§è¡Œå®Œæˆï¼Œå¼€å§‹æ„å»ºå“åº”...")
        
        # æ„å»ºå“åº”
        tasks = []
        if final_state.get("plan"):
            for task in final_state["plan"].tasks:
                tasks.append(TaskInfo(
                    task_id=task.task_id,
                    description=task.description,
                    tool=task.tool,
                    status=task.status,
                    result=str(task.result) if task.result else None,
                    error=task.error
                ))
        
        if final_state.get("error"):
            logger.error(f"âŒ æ‰§è¡Œå¤±è´¥: {final_state['error']}")
            return ChatResponse(
                success=False,
                error=final_state["error"],
                tasks=tasks
            )
        
        logger.success(f"âœ… è¯·æ±‚å¤„ç†æˆåŠŸï¼Œæœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(final_state.get('final_answer', ''))} å­—ç¬¦")
        logger.info(f"ä»»åŠ¡æ•°é‡: {len(tasks)}")
        
        return ChatResponse(
            success=True,
            final_answer=final_state.get("final_answer", ""),
            tasks=tasks
        )
        
    except Exception as e:
        logger.error(f"âŒ API é”™è¯¯: {str(e)}")
        import traceback
        logger.error(f"å®Œæ•´é”™è¯¯å †æ ˆ: {traceback.format_exc()}")
        log_step("API é”™è¯¯", str(e))
        log_step("API é”™è¯¯å †æ ˆ", traceback.format_exc())
        raise HTTPException(status_code=500, detail=f"æ‰§è¡Œå¤±è´¥: {str(e)}")


async def event_generator(request: ChatRequest) -> AsyncGenerator[str, None]:
    """
    æµå¼äº‹ä»¶ç”Ÿæˆå™¨
    ä»äº‹ä»¶é˜Ÿåˆ—ä¸­å®æ—¶è¯»å–æ‰§è¡Œè¿›åº¦å¹¶è¾“å‡º
    """
    global planner_graph, event_queue
    
    if not request.user_input or not request.user_input.strip():
        yield json.dumps({"type": "error", "content": "user_input ä¸èƒ½ä¸ºç©º"}, ensure_ascii=False) + "\n"
        return
    
    if planner_graph is None:
        yield json.dumps({"type": "error", "content": "æœåŠ¡æœªå®Œå…¨åˆå§‹åŒ–ï¼Œè¯·ç¨åå†è¯•"}, ensure_ascii=False) + "\n"
        return
    
    # æ¸…ç©ºé˜Ÿåˆ—
    await clear_events()
    
    # å‘é€å¼€å§‹ä¿¡å·
    yield json.dumps({"type": "start", "content": f"ğŸš€ å¼€å§‹å¤„ç†: {request.user_input}"}, ensure_ascii=False) + "\n"
    
    # æ„å»ºåˆå§‹çŠ¶æ€
    initial_state: PlannerState = {
        "user_input": request.user_input,
        "plan": None,
        "task_results": {},
        "final_answer": "",
        "error": None
    }
    
    full_answer = ""
    
    try:
        # åœ¨åå°å¯åŠ¨æ‰§è¡Œä»»åŠ¡
        async def run_graph():
            nonlocal full_answer
            try:
                async for chunk in planner_graph.astream(initial_state):
                    # èŠ‚ç‚¹å®Œæˆåï¼Œå…¨å±€çŠ¶æ€å·²ç»æ›´æ–°ï¼Œå¯ä»¥ä»äº‹ä»¶é˜Ÿåˆ—è¯»å–
                    pass
            except Exception as e:
                await event_queue.put({"type": "error", "content": f"æ‰§è¡Œé”™è¯¯: {str(e)}"})
        
        # å¯åŠ¨åå°ä»»åŠ¡
        task = asyncio.create_task(run_graph())
        
        # å®æ—¶è¯»å–äº‹ä»¶é˜Ÿåˆ—
        while True:
            try:
                # ç­‰å¾…äº‹ä»¶ï¼Œå¸¦è¶…æ—¶ä»¥æ”¯æŒå–æ¶ˆ
                event = await asyncio.wait_for(event_queue.get(), timeout=30.0)
                
                event_type = event.get("type", "info")
                content = event.get("content", "")
                
                if event_type == "answer_chunk":
                    # å¢é‡è¾“å‡ºç­”æ¡ˆ
                    full_answer += content
                    yield json.dumps({"type": "answer", "content": content}, ensure_ascii=False) + "\n"
                elif event_type == "done":
                    break
                elif event_type == "error":
                    yield json.dumps({"type": "error", "content": content}, ensure_ascii=False) + "\n"
                    task.cancel()
                    return
                else:
                    yield json.dumps({"type": event_type, "content": content}, ensure_ascii=False) + "\n"
                
            except asyncio.TimeoutError:
                # è¶…æ—¶ï¼Œæ£€æŸ¥ä»»åŠ¡æ˜¯å¦å®Œæˆ
                if task.done():
                    break
                continue
        
        # ç­‰å¾…ä»»åŠ¡å®Œæˆ
        try:
            await task
        except asyncio.CancelledError:
            pass
        
        # å‘é€å®Œæˆä¿¡å·
        yield json.dumps({"type": "done", "content": f"âœ… å¤„ç†å®Œæˆï¼Œæœ€ç»ˆç­”æ¡ˆé•¿åº¦: {len(full_answer)} å­—ç¬¦"}, ensure_ascii=False) + "\n"
        
    except asyncio.CancelledError:
        yield json.dumps({"type": "error", "content": "è¿æ¥å·²å–æ¶ˆ"}, ensure_ascii=False) + "\n"
    except Exception as e:
        import traceback
        log_step("æµå¼é”™è¯¯", str(e))
        yield json.dumps({"type": "error", "content": f"æ‰§è¡Œå¤±è´¥: {str(e)}"}, ensure_ascii=False) + "\n"


@app.post("/chat/stream")
async def chat_stream(request: ChatRequest):
    """
    æµå¼èŠå¤©æ¥å£
    
    é€šè¿‡ Server-Sent Events æµå¼è¾“å‡ºæ‰§è¡Œè¿›åº¦å’Œæœ€ç»ˆç»“æœ
    """
    logger.info(f"\n{'='*60}")
    logger.info("ğŸ“¥ æ”¶åˆ°æ–°çš„æµå¼ API è¯·æ±‚")
    logger.info(f"{'='*60}")
    logger.info(f"ç«¯ç‚¹: /chat/stream")
    logger.info(f"ç”¨æˆ·è¾“å…¥: {request.user_input}")
    logger.info(f"{'='*60}\n")
    
    return StreamingResponse(
        event_generator(request),
        media_type="text/plain",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "X-Accel-Buffering": "no"
        }
    )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "app:app",
        host=os.getenv("API_HOST", "0.0.0.0"),
        port=int(os.getenv("API_PORT", "8898")),
        reload=False
    )
