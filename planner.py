"""
Planner ä¸»å›¾æ¨¡å—
ä½¿ç”¨ LangChain å·¥å…·ç»‘å®šå’Œ LangGraph ToolNode
"""

import json
from typing import Dict, Any, Literal
from langgraph.graph import StateGraph, END, MessagesState
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

from states import PlannerState, Plan, Task
from utils import get_llm, log_step
from meta import build_planner_prompt
from worker import mcp_client
from tools import get_langchain_tools


# ============= èŠ‚ç‚¹å‡½æ•° =============

async def planning_node(state: PlannerState) -> PlannerState:
    """
    è§„åˆ’èŠ‚ç‚¹: ç”Ÿæˆ JSON æ ¼å¼çš„ä»»åŠ¡è®¡åˆ’
    """
    user_input = state["user_input"]
    
    print("\n" + "="*60)
    print("ğŸ“‹ è§„åˆ’èŠ‚ç‚¹ - å¼€å§‹æ€è€ƒ...")
    print("="*60)
    print(f"ç”¨æˆ·è¾“å…¥: {user_input}\n")
    print("ğŸ¤” LLM æ€è€ƒè¿‡ç¨‹:")
    print("-"*60)
    
    try:
        # è·å– MCP å·¥å…·ç”¨äºç”Ÿæˆæè¿°
        mcp_tools = await mcp_client.list_tools()
        log_step("è·å–å·¥å…·åˆ—è¡¨", f"å…± {len(mcp_tools)} ä¸ªå·¥å…·")
        
        # æ‰“å°å·¥å…·ä¿¡æ¯ç”¨äºè°ƒè¯•
        for tool in mcp_tools:
            log_step(f"å·¥å…·: {tool.name}", {
                "description": tool.description if hasattr(tool, 'description') else "æ— æè¿°"
            })
        
        # ç”ŸæˆåŒ…å«å·¥å…·ä¿¡æ¯çš„ prompt
        planner_prompt = build_planner_prompt(mcp_tools)
        
        log_step("Planner Prompt", planner_prompt[:500] + "...")  # åªæ‰“å°å‰500å­—ç¬¦
        
        # ä¸ä½¿ç”¨ bind_tools,è®© LLM è¿”å› JSON æ ¼å¼çš„è®¡åˆ’
        llm = get_llm(temperature=0.7)
        
        # è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’
        messages = [
            {"role": "system", "content": planner_prompt},
            {"role": "user", "content": user_input}
        ]
        
        print("\nğŸš€ å¼€å§‹è°ƒç”¨ LLM...")
        
        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        async for chunk in llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end='', flush=True)
                full_content += chunk.content
        
        print("\n")  # æ¢è¡Œ
        
        # ç›´æ¥ä½¿ç”¨æ”¶é›†åˆ°çš„å®Œæ•´å†…å®¹
        content = full_content
        log_step("LLM å“åº”", f"å®Œæ•´å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        
        # è§£æå“åº”
        if content:
            log_step("LLM è¿”å›å†…å®¹", content[:1000])  # æ‰“å°å‰1000å­—ç¬¦
            
            # å°è¯•è§£æ JSON æ ¼å¼çš„è®¡åˆ’
            try:
                import re
                
                # æå– JSON
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    json_str = content[start:end].strip()
                elif "```" in content:
                    start = content.find("```") + 3
                    end = content.find("```", start)
                    json_str = content[start:end].strip()
                else:
                    # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹
                    json_str = content.strip()
                
                log_step("æå–çš„ JSON", json_str)
                
                plan_data = json.loads(json_str)
                plan = Plan(**plan_data)
                
                log_step("ç”Ÿæˆçš„è®¡åˆ’", plan.model_dump())
                
                state["plan"] = plan
                state["task_results"] = {}
                
            except json.JSONDecodeError as e:
                log_step("JSON è§£æé”™è¯¯", f"ä½ç½®: {e.pos}, æ¶ˆæ¯: {e.msg}")
                log_step("åŸå§‹å†…å®¹", content)
                state["error"] = f"JSON è§£æå¤±è´¥: {str(e)}\nåŸå§‹å†…å®¹: {content[:200]}"
            except Exception as e:
                log_step("è§£æè®¡åˆ’å¤±è´¥", f"é”™è¯¯ç±»å‹: {type(e).__name__}, æ¶ˆæ¯: {str(e)}")
                import traceback
                log_step("å®Œæ•´é”™è¯¯å †æ ˆ", traceback.format_exc())
                state["error"] = f"è§£æè®¡åˆ’å¤±è´¥: {str(e)}"
        else:
            log_step("LLM å“åº”å¼‚å¸¸", "å†…å®¹ä¸ºç©º")
            state["error"] = "LLM æœªè¿”å›æœ‰æ•ˆå†…å®¹"
        
    except Exception as e:
        log_step("è§„åˆ’èŠ‚ç‚¹é”™è¯¯", f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        log_step("é”™è¯¯æ¶ˆæ¯", str(e))
        import traceback
        log_step("å®Œæ•´é”™è¯¯å †æ ˆ", traceback.format_exc())
        state["error"] = f"è§„åˆ’èŠ‚ç‚¹é”™è¯¯: {str(e)}"
    
    return state


async def execution_node(state: PlannerState) -> PlannerState:
    """
    æ‰§è¡ŒèŠ‚ç‚¹: ä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨
    æ™ºèƒ½å¤„ç† search_metrics å’Œ query_sales_summary_detail çš„ä¾èµ–å…³ç³»
    """
    plan = state.get("plan")
    if not plan:
        state["error"] = "æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’"
        return state
    
    log_step("æ‰§è¡ŒèŠ‚ç‚¹", f"å…± {len(plan.tasks)} ä¸ªä»»åŠ¡")
    
    try:
        # è·å– LangChain å·¥å…·
        tools = await get_langchain_tools(mcp_client)
        
        task_results = state.get("task_results", {})
        executed_tasks = set()
        
        # é¢„å¤„ç†ï¼šåˆ†æä»»åŠ¡å‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨ï¼Œè‡ªåŠ¨æ·»åŠ åˆ° depends_on
        for task in plan.tasks:
            for value in task.arguments.values():
                if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
                    ref_expr = value[2:-1]
                    # æå– task_idï¼ˆæ”¯æŒ task_id å’Œ task_id.field æ ¼å¼ï¼‰
                    ref_task_id = ref_expr.split('.')[0]
                    # å¦‚æœå¼•ç”¨çš„ä»»åŠ¡ä¸åœ¨ depends_on ä¸­ï¼Œæ·»åŠ è¿›å»
                    if ref_task_id != task.task_id and ref_task_id not in task.depends_on:
                        task.depends_on.append(ref_task_id)
                        log_step(f"è‡ªåŠ¨æ·»åŠ ä¾èµ–", f"{task.task_id} -> {ref_task_id}")
        
        # è¾…åŠ©å‡½æ•°ï¼šä» search_metrics ç»“æœä¸­è§£æ metric_name
        def extract_metric_name(search_result: str) -> str:
            """ä» search_metrics çš„ JSON ç»“æœä¸­æå– metric_name"""
            try:
                import json
                data = json.loads(search_result)
                if "results" in data and len(data["results"]) > 0:
                    first_result = data["results"][0]
                    if "metric_name" in first_result:
                        return first_result["metric_name"]
                return None
            except Exception as e:
                log_step("è§£æ metric_name å¤±è´¥", str(e))
                return None
        
        # è¾…åŠ©å‡½æ•°ï¼šæ£€æŸ¥æ˜¯å¦éœ€è¦è‡ªåŠ¨æ‰§è¡Œ search_metrics
        async def ensure_search_metrics(metric_input: str) -> str:
            """ç¡®ä¿ search_metrics å·²æ‰§è¡Œï¼Œè¿”å› metric_name"""
            # æ£€æŸ¥æ˜¯å¦å·²æœ‰ search_metrics ä»»åŠ¡æ‰§è¡Œè¿‡
            for executed_task_id in executed_tasks:
                result = task_results.get(executed_task_id)
                if result and not isinstance(result, dict) or "error" not in result:
                    try:
                        # å°è¯•ä»ç»“æœä¸­æå– metric_name
                        metric_name = extract_metric_name(str(result))
                        if metric_name:
                            log_step("ä»å·²æœ‰ä»»åŠ¡å¤ç”¨ metric_name", metric_name)
                            return metric_name
                    except:
                        pass
            
            # æ²¡æœ‰æ‰¾åˆ°ï¼Œæ‰§è¡Œ search_metrics
            log_step("æ‰§è¡Œ search_metrics", f"æŸ¥è¯¢æŒ‡æ ‡: {metric_input}")
            search_tool = next((t for t in tools if t.name == "search_metrics"), None)
            if search_tool:
                search_result = await search_tool.ainvoke({
                    "value": metric_input,
                    "column_name": "metric_name_cn",
                    "n_results": 1
                })
                
                log_step("search_metrics ç»“æœ", search_result)
                
                # æå– metric_name
                metric_name = extract_metric_name(str(search_result))
                if metric_name:
                    log_step("æå– metric_name", f"{metric_input} -> {metric_name}")
                    return metric_name
                else:
                    log_step("æœªæ‰¾åˆ°åŒ¹é…çš„ metric_name", f"ä½¿ç”¨åŸå§‹è¾“å…¥: {metric_input}")
                    return metric_input
            else:
                log_step("search_metrics å·¥å…·æœªæ‰¾åˆ°", "ä½¿ç”¨åŸå§‹è¾“å…¥")
                return metric_input
        
        # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œä»»åŠ¡
        while len(executed_tasks) < len(plan.tasks):
            # æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡
            ready_tasks = [
                task for task in plan.tasks
                if task.task_id not in executed_tasks
                and all(dep in executed_tasks for dep in task.depends_on)
            ]
            
            if not ready_tasks:
                remaining = [t for t in plan.tasks if t.task_id not in executed_tasks]
                state["error"] = f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–æˆ–æ— æ³•æ»¡è¶³çš„ä¾èµ–: {[t.task_id for t in remaining]}"
                break
            
            # æ‰§è¡Œå°±ç»ªçš„ä»»åŠ¡
            for task in ready_tasks:
                log_step(f"æ‰§è¡Œä»»åŠ¡ {task.task_id}", {
                    "description": task.description,
                    "tool": task.tool,
                    "arguments": task.arguments
                })
                
                try:
                    # è§£æå‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨
                    resolved_args = {}
                    for key, value in task.arguments.items():
                        if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
                            ref_expr = value[2:-1]
                            
                            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š${task_id} å’Œ ${task_id.field}
                            if '.' in ref_expr:
                                # æ ¼å¼ï¼š${task_id.field}
                                ref_task_id, ref_field = ref_expr.split('.', 1)
                                if ref_task_id in task_results:
                                    ref_result = task_results[ref_task_id]
                                    ref_task_obj = next((t for t in plan.tasks if t.task_id == ref_task_id), None)
                                    
                                    # å¦‚æœä¾èµ–çš„æ˜¯ search_metrics ä¸”æŒ‡å®šäº† fieldï¼Œæå–å¯¹åº”å­—æ®µ
                                    if ref_task_obj and ref_task_obj.tool == "search_metrics":
                                        try:
                                            import json
                                            data = json.loads(str(ref_result))
                                            if "results" in data and len(data["results"]) > 0:
                                                first_result = data["results"][0]
                                                if ref_field in first_result:
                                                    resolved_args[key] = first_result[ref_field]
                                                    log_step(f"ä» {ref_task_id}.{ref_field} æå–å€¼", first_result[ref_field])
                                                else:
                                                    log_step(f"å­—æ®µ {ref_field} ä¸å­˜åœ¨", f"å¯ç”¨å­—æ®µ: {list(first_result.keys())}")
                                                    resolved_args[key] = ref_result
                                            else:
                                                resolved_args[key] = ref_result
                                        except:
                                            resolved_args[key] = ref_result
                                    else:
                                        resolved_args[key] = ref_result
                                else:
                                    raise ValueError(f"Task dependency not found: {ref_task_id}")
                            else:
                                # æ ¼å¼ï¼š${task_id}
                                ref_task_id = ref_expr
                                if ref_task_id in task_results:
                                    # å¦‚æœä¾èµ–çš„æ˜¯ search_metrics ç»“æœï¼Œéœ€è¦æå– metric_name
                                    ref_result = task_results[ref_task_id]
                                    ref_task = next((t for t in plan.tasks if t.task_id == ref_task_id), None)
                                    if ref_task and ref_task.tool == "search_metrics":
                                        metric_name = extract_metric_name(str(ref_result))
                                        if metric_name:
                                            resolved_args[key] = metric_name
                                            log_step(f"ä» {ref_task_id} æå– metric_name", metric_name)
                                        else:
                                            resolved_args[key] = ref_result
                                    else:
                                        resolved_args[key] = ref_result
                                else:
                                    raise ValueError(f"Task dependency not found: {ref_task_id}")
                        else:
                            resolved_args[key] = value
                    
                    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœä½¿ç”¨ query_sales_summary_detail ä¸” metric_name ä¸æ˜¯ä¾èµ–å¼•ç”¨
                    if task.tool == "query_sales_summary_detail":
                        metric_name_input = resolved_args.get("metric_name", "")
                        # å¦‚æœ metric_name æ˜¯å­—ç¬¦ä¸²ä¸”ä¸æ˜¯ä¾èµ–å¼•ç”¨ï¼Œè‡ªåŠ¨è°ƒç”¨ search_metrics
                        if isinstance(metric_name_input, str) and not metric_name_input.startswith("${"):
                            log_step("è‡ªåŠ¨è°ƒç”¨ search_metrics", f"éœ€è¦æŸ¥è¯¢æŒ‡æ ‡: {metric_name_input}")
                            resolved_args["metric_name"] = await ensure_search_metrics(metric_name_input)
                    
                    # æ‰¾åˆ°å¯¹åº”çš„å·¥å…·
                    tool = next((t for t in tools if t.name == task.tool), None)
                    if not tool:
                        raise ValueError(f"Tool not found: {task.tool}")
                    
                    # æ‰§è¡Œå·¥å…·
                    result = await tool.ainvoke(resolved_args)
                    
                    task.status = "completed"
                    task.result = result
                    task_results[task.task_id] = result
                    
                    log_step(f"ä»»åŠ¡ {task.task_id} å®Œæˆ", {
                        "status": task.status,
                        "result": result
                    })
                    
                except Exception as e:
                    log_step(f"ä»»åŠ¡ {task.task_id} é”™è¯¯", str(e))
                    import traceback
                    log_step("é”™è¯¯å †æ ˆ", traceback.format_exc())
                    task.status = "failed"
                    task.error = str(e)
                    task_results[task.task_id] = {"error": str(e)}
                
                executed_tasks.add(task.task_id)
        
        state["task_results"] = task_results
        
    except Exception as e:
        log_step("æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯", str(e))
        import traceback
        log_step("å®Œæ•´é”™è¯¯å †æ ˆ", traceback.format_exc())
        state["error"] = f"æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {str(e)}"
    
    return state


async def final_answer_node(state: PlannerState) -> PlannerState:
    """
    æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹: æ±‡æ€»æ‰€æœ‰ä»»åŠ¡ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    """
    plan = state.get("plan")
    task_results = state.get("task_results", {})
    
    print("\n" + "="*60)
    print("ğŸ’¡ æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹ - ç”Ÿæˆç­”æ¡ˆ...")
    print("="*60)
    print("\nğŸ“Š ä»»åŠ¡æ‰§è¡Œæ‘˜è¦:")
    for task in plan.tasks:
        print(f"  - ä»»åŠ¡ {task.task_id}: {task.status}")
    
    # æ„å»ºç»“æœæ‘˜è¦
    summary = []
    for task in plan.tasks:
        summary.append(f"ä»»åŠ¡ {task.task_id} ({task.description}):")
        summary.append(f"  çŠ¶æ€: {task.status}")
        if task.result:
            summary.append(f"  ç»“æœ: {task.result}")
        if task.error:
            summary.append(f"  é”™è¯¯: {task.error}")
    
    summary_text = "\n".join(summary)
    
    try:
        llm = get_llm(temperature=0.3)
        messages = [
            {"role": "system", "content": "è¯·æ ¹æ®æ‰€æœ‰å­ä»»åŠ¡çš„æ‰§è¡Œç»“æœ,ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚è¦æ±‚ç®€æ´æ˜äº†,åŒ…å«å…³é”®ä¿¡æ¯ã€‚"},
            {"role": "user", "content": f"ä»»åŠ¡æ‰§è¡Œæ‘˜è¦:\n{summary_text}\n\nè¯·ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚"}
        ]
        
        print("\n" + "="*60)
        print("ğŸ¤– LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ:")
        print("-"*60)
        
        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        async for chunk in llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end='', flush=True)
                full_content += chunk.content
        
        print("\n" + "="*60 + "\n")
        
        state["final_answer"] = full_content
        
    except Exception as e:
        log_step("æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹é”™è¯¯", str(e))
        state["final_answer"] = f"ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}\n\nä»»åŠ¡æ‘˜è¦:\n{summary_text}"
    
    return state


def should_execute(state: PlannerState) -> str:
    """
    æ¡ä»¶è¾¹: åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œä»»åŠ¡
    """
    if state.get("error"):
        return "end"
    if not state.get("plan"):
        return "end"
    return "execute"


# ============= æ„å»ºä¸»å›¾ =============

def create_planner_graph() -> StateGraph:
    """
    åˆ›å»º Planner ä¸»å›¾
    
    æµç¨‹:
    1. planning_node: è§„åˆ’ä»»åŠ¡ (ä½¿ç”¨ bind_tools)
    2. execution_node: æ‰§è¡Œä»»åŠ¡ (ä½¿ç”¨ ToolNode)
    3. final_answer_node: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    """
    workflow = StateGraph(PlannerState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("planning", planning_node)
    workflow.add_node("execution", execution_node)
    workflow.add_node("final_answer", final_answer_node)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("planning")
    
    # æ·»åŠ è¾¹
    workflow.add_conditional_edges(
        "planning",
        should_execute,
        {
            "execute": "execution",
            "end": END
        }
    )
    
    workflow.add_edge("execution", "final_answer")
    workflow.add_edge("final_answer", END)
    
    return workflow.compile()
