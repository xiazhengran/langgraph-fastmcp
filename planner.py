"""
Planner ä¸»å›¾æ¨¡å—
ä½¿ç”¨ LangChain å·¥å…·ç»‘å®šå’Œ LangGraph ToolNode
"""

import json
from typing import Dict, Any, Literal
from langgraph.graph import StateGraph, END, MessagesState
from langgraph.prebuilt import ToolNode
from langchain_core.messages import HumanMessage, AIMessage, ToolMessage

from states import PlannerState, Plan, Task
from utils import get_llm, log_step
from meta import build_planner_prompt
from worker import mcp_client
from tools import get_langchain_tools


# ============= èŠ‚ç‚¹å‡½æ•° =============

async def planning_node(state: PlannerState) -> PlannerState:
    """
    è§„åˆ’èŠ‚ç‚¹: ç”Ÿæˆ JSON æ ¼å¼çš„ä»»åŠ¡è®¡åˆ’
    """
    user_input = state["user_input"]
    
    print("\n" + "="*60)
    print("ğŸ“‹ è§„åˆ’èŠ‚ç‚¹ - å¼€å§‹æ€è€ƒ...")
    print("="*60)
    print(f"ç”¨æˆ·è¾“å…¥: {user_input}\n")
    print("ğŸ¤” LLM æ€è€ƒè¿‡ç¨‹:")
    print("-"*60)
    
    try:
        # è·å– MCP å·¥å…·ç”¨äºç”Ÿæˆæè¿°
        mcp_tools = await mcp_client.list_tools()
        log_step("è·å–å·¥å…·åˆ—è¡¨", f"å…± {len(mcp_tools)} ä¸ªå·¥å…·")
        
        # æ‰“å°å·¥å…·ä¿¡æ¯ç”¨äºè°ƒè¯•
        for tool in mcp_tools:
            log_step(f"å·¥å…·: {tool.name}", {
                "description": tool.description if hasattr(tool, 'description') else "æ— æè¿°"
            })
        
        # ç”ŸæˆåŒ…å«å·¥å…·ä¿¡æ¯çš„ prompt
        planner_prompt = build_planner_prompt(mcp_tools)
        
        log_step("Planner Prompt", planner_prompt[:500] + "...")  # åªæ‰“å°å‰500å­—ç¬¦
        
        # ä¸ä½¿ç”¨ bind_tools,è®© LLM è¿”å› JSON æ ¼å¼çš„è®¡åˆ’
        llm = get_llm(temperature=0.7)
        
        # è°ƒç”¨ LLM ç”Ÿæˆè®¡åˆ’
        messages = [
            {"role": "system", "content": planner_prompt},
            {"role": "user", "content": user_input}
        ]
        
        print("\nğŸš€ å¼€å§‹è°ƒç”¨ LLM...")
        
        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        async for chunk in llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end='', flush=True)
                full_content += chunk.content
        
        print("\n")  # æ¢è¡Œ
        
        # ç›´æ¥ä½¿ç”¨æ”¶é›†åˆ°çš„å®Œæ•´å†…å®¹
        content = full_content
        log_step("LLM å“åº”", f"å®Œæ•´å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦")
        
        # è§£æå“åº”
        if content:
            log_step("LLM è¿”å›å†…å®¹", content[:1000])  # æ‰“å°å‰1000å­—ç¬¦
            
            # å°è¯•è§£æ JSON æ ¼å¼çš„è®¡åˆ’
            try:
                import re
                
                # æå– JSON
                if "```json" in content:
                    start = content.find("```json") + 7
                    end = content.find("```", start)
                    json_str = content[start:end].strip()
                elif "```" in content:
                    start = content.find("```") + 3
                    end = content.find("```", start)
                    json_str = content[start:end].strip()
                else:
                    # å°è¯•ç›´æ¥è§£ææ•´ä¸ªå†…å®¹
                    json_str = content.strip()
                
                log_step("æå–çš„ JSON", json_str)
                
                plan_data = json.loads(json_str)
                plan = Plan(**plan_data)
                
                log_step("ç”Ÿæˆçš„è®¡åˆ’", plan.model_dump())
                
                state["plan"] = plan
                state["task_results"] = {}
                
            except json.JSONDecodeError as e:
                log_step("JSON è§£æé”™è¯¯", f"ä½ç½®: {e.pos}, æ¶ˆæ¯: {e.msg}")
                log_step("åŸå§‹å†…å®¹", content)
                state["error"] = f"JSON è§£æå¤±è´¥: {str(e)}\nåŸå§‹å†…å®¹: {content[:200]}"
            except Exception as e:
                log_step("è§£æè®¡åˆ’å¤±è´¥", f"é”™è¯¯ç±»å‹: {type(e).__name__}, æ¶ˆæ¯: {str(e)}")
                import traceback
                log_step("å®Œæ•´é”™è¯¯å †æ ˆ", traceback.format_exc())
                state["error"] = f"è§£æè®¡åˆ’å¤±è´¥: {str(e)}"
        else:
            log_step("LLM å“åº”å¼‚å¸¸", "å†…å®¹ä¸ºç©º")
            state["error"] = "LLM æœªè¿”å›æœ‰æ•ˆå†…å®¹"
        
    except Exception as e:
        log_step("è§„åˆ’èŠ‚ç‚¹é”™è¯¯", f"é”™è¯¯ç±»å‹: {type(e).__name__}")
        log_step("é”™è¯¯æ¶ˆæ¯", str(e))
        import traceback
        log_step("å®Œæ•´é”™è¯¯å †æ ˆ", traceback.format_exc())
        state["error"] = f"è§„åˆ’èŠ‚ç‚¹é”™è¯¯: {str(e)}"
    
    return state


# ============= è¾…åŠ©å‡½æ•° =============

def extract_metric_name(search_result: str) -> str | None:
    """ä» search_metrics çš„ JSON ç»“æœä¸­æå– metric_name"""
    try:
        import json
        data = json.loads(search_result)
        if "results" in data and len(data["results"]) > 0:
            first_result = data["results"][0]
            if "metric_name" in first_result:
                return first_result["metric_name"]
        return None
    except Exception as e:
        log_step("è§£æ metric_name å¤±è´¥", str(e))
        return None


def extract_field_from_result(result: str, field: str) -> Any:
    """ä»ä»»åŠ¡ç»“æœä¸­æå–æŒ‡å®šå­—æ®µ"""
    try:
        import json
        data = json.loads(result)
        if "results" in data and len(data["results"]) > 0:
            first_result = data["results"][0]
            if field in first_result:
                return first_result[field]
        return result
    except Exception:
        return result


def resolve_task_dependencies(task_results: dict[str, Any], plan: Plan, task: Task) -> dict[str, Any]:
    """
    è§£æä»»åŠ¡å‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨ï¼Œå°† ${task_id} æˆ– ${task_id.field} æ ¼å¼æ›¿æ¢ä¸ºå®é™…å€¼
    
    Args:
        task_results: å·²æ‰§è¡Œä»»åŠ¡çš„ç»“æœå­—å…¸
        plan: ä»»åŠ¡è®¡åˆ’
        task: å½“å‰ä»»åŠ¡
    
    Returns:
        resolved_args: è§£æåçš„å‚æ•°å­—å…¸
    """
    resolved_args = {}
    
    for key, value in task.arguments.items():
        if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
            ref_expr = value[2:-1]
            
            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š${task_id} å’Œ ${task_id.field}
            if '.' in ref_expr:
                # æ ¼å¼ï¼š${task_id.field}
                ref_task_id, ref_field = ref_expr.split('.', 1)
                if ref_task_id not in task_results:
                    raise ValueError(f"Task dependency not found: {ref_task_id}")
                
                ref_result = task_results[ref_task_id]
                ref_task_obj = next((t for t in plan.tasks if t.task_id == ref_task_id), None)
                
                # å¦‚æœä¾èµ–çš„æ˜¯ search_metrics ä¸”æŒ‡å®šäº† fieldï¼Œä»ç»“æœä¸­æå–å¯¹åº”å­—æ®µ
                if ref_task_obj and ref_task_obj.tool == "search_metrics":
                    resolved_value = extract_field_from_result(str(ref_result), ref_field)
                    log_step(f"ä» {ref_task_id}.{ref_field} æå–å€¼", resolved_value)
                    resolved_args[key] = resolved_value
                else:
                    resolved_args[key] = ref_result
            else:
                # æ ¼å¼ï¼š${task_id}
                ref_task_id = ref_expr
                if ref_task_id not in task_results:
                    raise ValueError(f"Task dependency not found: {ref_task_id}")
                
                ref_result = task_results[ref_task_id]
                ref_task = next((t for t in plan.tasks if t.task_id == ref_task_id), None)
                
                # å¦‚æœä¾èµ–çš„æ˜¯ search_metrics ç»“æœï¼Œè‡ªåŠ¨æå– metric_name
                if ref_task and ref_task.tool == "search_metrics":
                    metric_name = extract_metric_name(str(ref_result))
                    if metric_name:
                        resolved_args[key] = metric_name
                        log_step(f"ä» {ref_task_id} æå– metric_name", metric_name)
                    else:
                        resolved_args[key] = ref_result
                else:
                    resolved_args[key] = ref_result
        else:
            resolved_args[key] = value
    
    return resolved_args


def auto_add_dependencies(plan: Plan) -> None:
    """
    é¢„å¤„ç†ï¼šåˆ†æä»»åŠ¡å‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨ï¼Œè‡ªåŠ¨æ·»åŠ åˆ° depends_on
    
    Args:
        plan: ä»»åŠ¡è®¡åˆ’
    """
    for task in plan.tasks:
        for value in task.arguments.values():
            if isinstance(value, str) and value.startswith("${") and value.endswith("}"):
                ref_expr = value[2:-1]
                ref_task_id = ref_expr.split('.')[0]
                if ref_task_id != task.task_id and ref_task_id not in task.depends_on:
                    task.depends_on.append(ref_task_id)
                    log_step(f"è‡ªåŠ¨æ·»åŠ ä¾èµ–", f"{task.task_id} -> {ref_task_id}")


async def ensure_search_metrics(tools: list, metric_input: str) -> str:
    """
    ç¡®ä¿ search_metrics å·²æ‰§è¡Œï¼Œè¿”å› metric_name
    
    Args:
        tools: å¯ç”¨çš„å·¥å…·åˆ—è¡¨
        metric_input: æŒ‡æ ‡è¾“å…¥å€¼
    
    Returns:
        metric_name: æå–çš„ metric_name
    """
    search_tool = next((t for t in tools if t.name == "search_metrics"), None)
    if not search_tool:
        log_step("search_metrics å·¥å…·æœªæ‰¾åˆ°", "ä½¿ç”¨åŸå§‹è¾“å…¥")
        return metric_input
    
    log_step("æ‰§è¡Œ search_metrics", f"æŸ¥è¯¢æŒ‡æ ‡: {metric_input}")
    search_result = await search_tool.ainvoke({
        "value": metric_input,
        "column_name": "metric_name_cn",
        "n_results": 1
    })
    log_step("search_metrics ç»“æœ", search_result)
    
    metric_name = extract_metric_name(str(search_result))
    if metric_name:
        log_step("æå– metric_name", f"{metric_input} -> {metric_name}")
        return metric_name
    else:
        log_step("æœªæ‰¾åˆ°åŒ¹é…çš„ metric_name", f"ä½¿ç”¨åŸå§‹è¾“å…¥: {metric_input}")
        return metric_input


# ============= èŠ‚ç‚¹å‡½æ•° =============

async def execution_node(state: PlannerState) -> PlannerState:
    """
    æ‰§è¡ŒèŠ‚ç‚¹: ä½¿ç”¨ ToolNode æ‰§è¡Œå·¥å…·è°ƒç”¨
    æ™ºèƒ½å¤„ç† search_metrics å’Œ query_sales_summary_detail çš„ä¾èµ–å…³ç³»
    """
    plan = state.get("plan")
    if not plan:
        state["error"] = "æ²¡æœ‰å¯æ‰§è¡Œçš„è®¡åˆ’"
        return state
    
    log_step("æ‰§è¡ŒèŠ‚ç‚¹", f"å…± {len(plan.tasks)} ä¸ªä»»åŠ¡")
    
    try:
        # è·å– LangChain å·¥å…·
        tools = await get_langchain_tools(mcp_client)
        
        task_results = state.get("task_results", {})
        executed_tasks = set()
        
        # é¢„å¤„ç†ï¼šè‡ªåŠ¨åˆ†æå¹¶æ·»åŠ ä»»åŠ¡ä¾èµ–
        auto_add_dependencies(plan)
        
        # æŒ‰ä¾èµ–é¡ºåºæ‰§è¡Œä»»åŠ¡
        while len(executed_tasks) < len(plan.tasks):
            # æ‰¾åˆ°å¯ä»¥æ‰§è¡Œçš„ä»»åŠ¡
            ready_tasks = [
                task for task in plan.tasks
                if task.task_id not in executed_tasks
                and all(dep in executed_tasks for dep in task.depends_on)
            ]
            
            if not ready_tasks:
                remaining = [t for t in plan.tasks if t.task_id not in executed_tasks]
                state["error"] = f"æ£€æµ‹åˆ°å¾ªç¯ä¾èµ–æˆ–æ— æ³•æ»¡è¶³çš„ä¾èµ–: {[t.task_id for t in remaining]}"
                break
            
            # æ‰§è¡Œå°±ç»ªçš„ä»»åŠ¡
            for task in ready_tasks:
                log_step(f"æ‰§è¡Œä»»åŠ¡ {task.task_id}", {
                    "description": task.description,
                    "tool": task.tool,
                    "arguments": task.arguments
                })
                
                try:
                    # è§£æå‚æ•°ä¸­çš„ä¾èµ–å¼•ç”¨
                    resolved_args = resolve_task_dependencies(task_results, plan, task)
                    
                    # ç‰¹æ®Šå¤„ç†ï¼šquery_sales_summary_detail éœ€è¦æŸ¥è¯¢ metric_name
                    if task.tool == "query_sales_summary_detail":
                        metric_name_input = resolved_args.get("metric_name", "")
                        if isinstance(metric_name_input, str) and not metric_name_input.startswith("${"):
                            log_step("è‡ªåŠ¨è°ƒç”¨ search_metrics", f"éœ€è¦æŸ¥è¯¢æŒ‡æ ‡: {metric_name_input}")
                            resolved_args["metric_name"] = await ensure_search_metrics(tools, metric_name_input)
                    
                    # æ‰¾åˆ°å¯¹åº”çš„å·¥å…·
                    tool = next((t for t in tools if t.name == task.tool), None)
                    if not tool:
                        raise ValueError(f"Tool not found: {task.tool}")
                    
                    # æ‰§è¡Œå·¥å…·
                    result = await tool.ainvoke(resolved_args)
                    
                    task.status = "completed"
                    task.result = result
                    task_results[task.task_id] = result
                    
                    log_step(f"ä»»åŠ¡ {task.task_id} å®Œæˆ", {
                        "status": task.status,
                        "result": result
                    })
                    
                except Exception as e:
                    log_step(f"ä»»åŠ¡ {task.task_id} é”™è¯¯", str(e))
                    import traceback
                    log_step("é”™è¯¯å †æ ˆ", traceback.format_exc())
                    task.status = "failed"
                    task.error = str(e)
                    task_results[task.task_id] = {"error": str(e)}
                
                executed_tasks.add(task.task_id)
        
        state["task_results"] = task_results
        
    except Exception as e:
        log_step("æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯", str(e))
        import traceback
        log_step("å®Œæ•´é”™è¯¯å †æ ˆ", traceback.format_exc())
        state["error"] = f"æ‰§è¡ŒèŠ‚ç‚¹é”™è¯¯: {str(e)}"
    
    return state


async def final_answer_node(state: PlannerState) -> PlannerState:
    """
    æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹: æ±‡æ€»æ‰€æœ‰ä»»åŠ¡ç»“æœç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    """
    plan = state.get("plan")
    task_results = state.get("task_results", {})
    
    print("\n" + "="*60)
    print("ğŸ’¡ æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹ - ç”Ÿæˆç­”æ¡ˆ...")
    print("="*60)
    print("\nğŸ“Š ä»»åŠ¡æ‰§è¡Œæ‘˜è¦:")
    for task in plan.tasks:
        print(f"  - ä»»åŠ¡ {task.task_id}: {task.status}")
    
    # æ„å»ºç»“æœæ‘˜è¦
    summary = []
    for task in plan.tasks:
        summary.append(f"ä»»åŠ¡ {task.task_id} ({task.description}):")
        summary.append(f"  çŠ¶æ€: {task.status}")
        if task.result:
            summary.append(f"  ç»“æœ: {task.result}")
        if task.error:
            summary.append(f"  é”™è¯¯: {task.error}")
    
    summary_text = "\n".join(summary)
    
    try:
        llm = get_llm(temperature=0.3)
        user_input = state.get("user_input", "")
        messages = [
            {"role": "system", "content": "è¯·æ ¹æ®æ‰€æœ‰å­ä»»åŠ¡çš„æ‰§è¡Œç»“æœ,ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆã€‚è¦æ±‚ç®€æ´æ˜äº†,åŒ…å«å…³é”®ä¿¡æ¯ã€‚"},
            {"role": "user", "content": f"ç”¨æˆ·åŸå§‹é—®é¢˜: {user_input}\n\næ ¹æ®ä»»åŠ¡æ‰§è¡Œæ‘˜è¦,è¯·ç”Ÿæˆç”¨æˆ·æƒ³è¦äº†è§£çš„æœ€ç»ˆç­”æ¡ˆã€‚\n\nä»»åŠ¡æ‰§è¡Œæ‘˜è¦:\n{summary_text}"}
        ]
        
        print("\n" + "="*60)
        print("ğŸ¤– LLM ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ:")
        print("-"*60)
        
        # ä½¿ç”¨æµå¼è¾“å‡º
        full_content = ""
        async for chunk in llm.astream(messages):
            if hasattr(chunk, 'content') and chunk.content:
                print(chunk.content, end='', flush=True)
                full_content += chunk.content
        
        print("\n" + "="*60 + "\n")
        
        state["final_answer"] = full_content
        
    except Exception as e:
        log_step("æœ€ç»ˆç­”æ¡ˆèŠ‚ç‚¹é”™è¯¯", str(e))
        state["final_answer"] = f"ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆæ—¶å‡ºé”™: {str(e)}\n\nä»»åŠ¡æ‘˜è¦:\n{summary_text}"
    
    return state


def should_execute(state: PlannerState) -> str:
    """
    æ¡ä»¶è¾¹: åˆ¤æ–­æ˜¯å¦åº”è¯¥æ‰§è¡Œä»»åŠ¡
    """
    if state.get("error"):
        return "end"
    if not state.get("plan"):
        return "end"
    return "execute"


# ============= æ„å»ºä¸»å›¾ =============

def create_planner_graph() -> StateGraph:
    """
    åˆ›å»º Planner ä¸»å›¾
    
    æµç¨‹:
    1. planning_node: è§„åˆ’ä»»åŠ¡ (ä½¿ç”¨ bind_tools)
    2. execution_node: æ‰§è¡Œä»»åŠ¡ (ä½¿ç”¨ ToolNode)
    3. final_answer_node: ç”Ÿæˆæœ€ç»ˆç­”æ¡ˆ
    """
    workflow = StateGraph(PlannerState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("planning", planning_node)
    workflow.add_node("execution", execution_node)
    workflow.add_node("final_answer", final_answer_node)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("planning")
    
    # æ·»åŠ è¾¹
    workflow.add_conditional_edges(
        "planning",
        should_execute,
        {
            "execute": "execution",
            "end": END
        }
    )
    
    workflow.add_edge("execution", "final_answer")
    workflow.add_edge("final_answer", END)
    
    return workflow.compile()
